{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "022be9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b571994",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_card = 'bert-base-uncased'\n",
    "\n",
    "# Domain-pre-training corpora\n",
    "dpt_corpus_train = 'data/dapt_train.txt'\n",
    "dpt_corpus_train_data_selected = 'data/dapt_train_data_selected.txt'  # Optional: If you want to use data selection for DAPT\n",
    "dpt_corpus_val = 'data/dapt_val.txt'  # Optional: If you want to use a validation set for DAPT\n",
    "\n",
    "# Fine-tuning corpora\n",
    "# If there are multiple downstream NLP tasks/corpora, you can concatenate those files together\n",
    "ft_corpus_train = 'data/ft_train.txt'\n",
    "\n",
    "# how should the ft_train.txt look like? ans = \"Each line in the ft_train.txt file should represent a single training example for the fine-tuning task. The format of each line will depend on the specific NLP task you are working on. Here are some common formats for different tasks:\n",
    "# 1. Text Classification:\n",
    "#    Each line contains the text followed by a tab and then the label.\n",
    "#    Example:\n",
    "#    ```\n",
    "#    This is a positive review.    positive\n",
    "#    This is a negative review.    negative\n",
    "#    ```\n",
    "# should it be a csv or txt?\n",
    "# ans = \"The ft_train.txt file can be either a plain text file (.txt) or a CSV file (.csv), depending on your preference and the tools you are using. If you choose to use a CSV file, make sure to properly format it with commas separating the fields and include headers if necessary. For example, a CSV format for text classification might look like this:\n",
    "# ```\n",
    "#     text,label\n",
    "#     This is a positive review.,positive\n",
    "#     This is a negative review.,negative\n",
    "#     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86943416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\ner\\nerenv\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_card)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78a45000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70730171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data into memory\n",
    "fine_tuning_texts = Path(ft_corpus_train).read_text().splitlines()\n",
    "training_texts = Path(dpt_corpus_train).read_text().splitlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfd341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def split_long_documents(texts, max_tokens=512):\n",
    "    \"\"\"\n",
    "    Split each document into chunks with <= max_tokens tokens.\n",
    "    Returns a flat list of documents.\n",
    "    \"\"\"\n",
    "    split_docs = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.tokenize(text)  # tokenize to WordPiece tokens\n",
    "        # Split tokens into chunks of max_tokens\n",
    "        for i in range(0, len(tokens), max_tokens):\n",
    "            chunk_tokens = tokens[i:i + max_tokens]\n",
    "            # Convert back to string\n",
    "            chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
    "            split_docs.append(chunk_text)\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb9bbf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus length: 10000\n",
      "Fine-tuning corpus length: 10000\n"
     ]
    }
   ],
   "source": [
    "# Assume you already loaded your lines\n",
    "# training_texts = list of in-domain texts\n",
    "# fine_tuning_texts = list of fine-tuning texts\n",
    "\n",
    "training_texts = split_long_documents(training_texts, max_tokens=512)\n",
    "fine_tuning_texts = split_long_documents(fine_tuning_texts, max_tokens=512)\n",
    "\n",
    "print(\"Training corpus length:\", len(training_texts))\n",
    "print(\"Fine-tuning corpus length:\", len(fine_tuning_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11f625c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from transformers_domain_adaptation import DataSelector\n",
    "\n",
    "\n",
    "selector = DataSelector(\n",
    "    keep=0.5,  # TODO Replace with `keep`\n",
    "    tokenizer=tokenizer,\n",
    "    # similarity_metrics=['euclidean'],\n",
    "    similarity_metrics=['cosine'],\n",
    "    diversity_metrics=[\n",
    "        \"type_token_ratio\",\n",
    "        \"entropy\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7ab70b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load text data into memory\n",
    "# fine_tuning_texts = Path(ft_corpus_train).read_text().splitlines()\n",
    "# training_texts = Path(dpt_corpus_train).read_text().splitlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61fe3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tuning_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac7af678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "41a5d221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fine_tuning_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a96723bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (73387 > 512). Running this sequence through the model will result in indexing errors\n",
      "computing similarity:   0%|          | 0/1 [00:00<?, ?metric/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m selector\u001b[38;5;241m.\u001b[39mfit(fine_tuning_texts)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Select relevant documents from in-domain training corpus\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m selected_corpus \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save selected corpus to disk under `dpt_corpus_train_data_selected`\u001b[39;00m\n\u001b[0;32m      8\u001b[0m Path(dpt_corpus_train_data_selected)\u001b[38;5;241m.\u001b[39mwrite_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(selected_corpus));\n",
      "File \u001b[1;32mk:\\ner\\nerenv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mk:\\ner\\nerenv\\lib\\site-packages\\transformers_domain_adaptation\\data_selection\\data_selector.py:146\u001b[0m, in \u001b[0;36mDataSelector.transform\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, docs: Corpus) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Corpus:\n\u001b[0;32m    138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a relevant subset of documents from the training corpus based on the provided data selection metrics.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m        A subset of relevant :obj:`docs` for domain pre-training\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     composite_scores \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomposite\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    149\u001b[0m     n_select \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(docs))\n\u001b[0;32m    151\u001b[0m     )\n",
      "File \u001b[1;32mk:\\ner\\nerenv\\lib\\site-packages\\transformers_domain_adaptation\\data_selection\\data_selector.py:160\u001b[0m, in \u001b[0;36mDataSelector.compute_metrics\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, docs: Corpus) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    158\u001b[0m     scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[1;32m--> 160\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_similarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_diversities(docs),\n\u001b[0;32m    162\u001b[0m         ],\n\u001b[0;32m    163\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# Ensure metrics are normalized, before combining them into a composite score\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m    168\u001b[0m         RobustScaler()\u001b[38;5;241m.\u001b[39mfit_transform(scores), columns\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    169\u001b[0m     )\n",
      "File \u001b[1;32mk:\\ner\\nerenv\\lib\\site-packages\\transformers_domain_adaptation\\data_selection\\data_selector.py:190\u001b[0m, in \u001b[0;36mDataSelector.compute_similarities\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m    189\u001b[0m     sim_func \u001b[38;5;241m=\u001b[39m similarity_func_factory(metric)\n\u001b[1;32m--> 190\u001b[0m     similarities[metric] \u001b[38;5;241m=\u001b[39m \u001b[43msim_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mterm_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mft_term_dist_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarities\n",
      "File \u001b[1;32mk:\\ner\\nerenv\\lib\\site-packages\\transformers_domain_adaptation\\data_selection\\metrics\\similarity.py:49\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(repr1, repr2)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcosine_similarity\u001b[39m(repr1: np\u001b[38;5;241m.\u001b[39mndarray, repr2: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate cosine similarity (https://en.wikipedia.org/wiki/Cosine_similarity).\"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrepr1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     50\u001b[0m         repr1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(repr1, \u001b[38;5;28mlen\u001b[39m(repr2), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(repr2) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "# Fit on fine-tuning corpus\n",
    "selector.fit(fine_tuning_texts)\n",
    "\n",
    "# Select relevant documents from in-domain training corpus\n",
    "selected_corpus = selector.transform(training_texts)\n",
    "\n",
    "# Save selected corpus to disk under `dpt_corpus_train_data_selected`\n",
    "Path(dpt_corpus_train_data_selected).write_text('\\n'.join(selected_corpus));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d16663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987356e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
